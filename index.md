---
layout: default
---


# Public Datasets
+ [Dataset Finder](#dataset-finder)
+ [Image Datasets](#image-datasets)
    - [Facial Recognition](#machine-translation)
    - [Action Recognition](#action-recognition)
    - [Object Detection and Recognition](#object-detection-and-recognition)
    - [Handwriting and character recognition](#handwriting-and-character-recognition)
    - [Aerial images](#aerial-images)
    - [Other images](#other-images)

+ [Text Datasets](#text-data)
    - [Reviews](#reviews)
    - [News Articles](#news-articles)

+ [Voice Datasets](#voice-datasets)
    
+ [Machine Translation](#machine-translation)


## Dataset Finder
* [Kaggle](https://www.kaggle.com/): 
A data science site that contains a variety of externally-contributed 
interesting datasets. You can find all kinds of niche datasets in its 
master list, from ramen ratings to basketball data to and even Seattle 
pet licenses.

* [UCI Machine Learning Repository](http://mlr.cs.umass.edu/ml/): 
One of the oldest sources of datasets on the web, and a great first 
stop when looking for interesting datasets. Although the data sets are 
user-contributed, and thus have varying levels of cleanliness, 
the vast majority are clean. You can download data directly from 
the UCI Machine Learning repository, without registration.


* [Google Dataset Search](https://toolbox.google.com/datasetsearch): 
 Thanks to Google’s acquisition of Schema.org the metadata for datasets 
 is now recognized by Google’s knowledge graph.  This is in beta

* [Google Public Datasets](https://cloud.google.com/public-datasets/): 
Public Datasets on Google Cloud Platform makes it easy for users to access 
and analyze data in the cloud. These datasets are freely hosted and 
accessible using a variety of data warehouse and analytics software, 
from open source Apache Spark to cutting edge Google technologies 
like Google BigQuery and Google Cloud Dataflow. From structured genomic 
or encyclopedic data to unstructured climate data, Public Datasets provide 
a playground for those new to big data and data analysis and a powerful 
repository for skilled researchers. You can also integrate with your 
application to add valuable insights for your users. Whatever your use case, 
these datasets are freely available on GCP.


* [Microsoft Research Open Data](https://msropendata.com/): 
A collection of free datasets from Microsoft Research to advance 
state-of-the-art research in areas such as natural language processing, 
computer vision, and domain specific sciences. Download or copy directly 
to a cloud-based Data Science Virtual Machine for a seamless development 
experience. Categpries include Biology, Engineering, Healthcare, Mathematics,
Social Science, Computer Science, Environmental Science, Information Science and Physics.
MS Research Open Data doesn’t search the entire web, but rather makes available 
53 previously proprietary datasets all in the realm of deep learning, both 
text/speech and image.

* [Open Data on AWS](https://registry.opendata.aws/): 
The Registry of Open Data on AWS makes it easy to find datasets made publicly available through AWS services.
Browse available data and learn how to register your own datasets at: https://registry.opendata.aws


* [Academic Torrents](http://academictorrents.com/): 
A distributed system for sharing enormous datasets - for researchers, 
by researchers. The result is a scalable, secure, and fault-tolerant repository 
for data, with blazing fast download speeds


* [Github Awesome Public Datasets](https://github.com/awesomedata/awesome-public-datasets): 
This list of a topic-centric public data sources in high quality. 
They are collected and tidied from blogs, answers, and user responses. 
Most of the data sets listed below are free, however, some are not.  565 data sets.

* [Figure Eight](https://www.figure-eight.com/datasets/): 
This commercial provider of human-in-the-loop data currently offers only eight datasets.  The 
reason for their inclusion here is unique.  Figure Eight makes its reputation by 
providing accurate data, especially enhancing the accuracy of its client’s data. 

* [Skymind](https://skymind.ai/wiki/open-datasets): 
Skymind is a commercial platform to rapidly prototype, deploy, maintain, and retrain 
machine learning models.  They offer 101 datasets from a variety of sources that 
cover Natural-Image, Geospatial, Facial, Video, Text , Question answering, Sentiment, 
Recommendation and ranking systems, Networks and Graphs, Speech Datasets, Symbolic Music, 
Health & Biology, and Government & statistical data sets.

* [Yahoo Webscope Program](https://webscope.sandbox.yahoo.com/): 
The Yahoo Webscope Program is a reference library of interesting and scientifically useful datasets for non-commercial use by academics and other scientists.
All datasets have been reviewed to conform to Yahoo's data protection standards, including strict controls on privacy. We have a number of datasets that we are excited to share with you.


* [Stanford Large Network Dataset Collection](https://snap.stanford.edu/data/): 

* [Stanford Biomedical Network Dataset Collection](https://snap.stanford.edu/biodata/index.html/): 

* [Group Lens](https://grouplens.org/datasets/):
GroupLens Research has collected and made available several datasets. MovieLens, WikiLens, Book-Crossing, Jester
EachMovie, HetRec2011, Serendioity 2018, Personality 2018

* [Edinburgh Data Share](https://datashare.is.ed.ac.uk/):
Edinburgh DataShare is a digital repository of research data produced at the University of Edinburgh, hosted by Information Services. Edinburgh University researchers who have produced research data associated with an existing or forthcoming publication, or which has potential use for other researchers, are invited to upload their dataset for sharing and safekeeping. A persistent identifier and suggested citation will be provided.

* [Dataturks](https://dataturks.com/projects/trending):
Data Annotation Platform. Image Bounding, Document Annotation, NLP and Text Annotations. #HumanInTheLoop #AI, #TrainingData for #MachineLearning.



## Image Datasets
* [Diversity in Faces Dataset](https://www.research.ibm.com/artificial-intelligence/trusted-ai/diversity-in-faces/):
The Diversity in Faces(DiF)is a large and diverse dataset that seeks to 
advance the study of fairness and accuracy in facial recognition technology.
The first of its kind available to the global research community,
DiF provides a dataset of annotations of 1 million human facial images.

* [ADE20K](http://groups.csail.mit.edu/vision/datasets/ADE20K/): 
Semantic Understanding of Scenes through ADE20K Dataset. Bolei Zhou, Hang Zhao, Xavier Puig, Tete Xiao, Sanja Fidler, Adela Barriuso and Antonio Torralba. International Journal on Computer Vision (IJCV).

* [MURA (healthcare)](https://stanfordmlgroup.github.io/competitions/mura/): 
MURA (musculoskeletal radiographs) is a large dataset of bone X-rays. Algorithms are tasked with determining whether an X-ray study is normal or abnormal.

* [Labelme](http://labelme.csail.mit.edu/Release3.0/browserTools/php/dataset.php): 
 A large dataset of annotated images.

* [ImageNet](http://image-net.org/): 
The de-facto image dataset for new algorithms. Is organized according to the WordNet hierarchy, in which each node of the hierarchy is depicted by hundreds and thousands of images.

#### Facial Recognition
* [FERET (facial recognition technology)](https://www.nist.gov/itl/iad/image-group/color-feret-database): 
11338 images of 1199 individuals in different positions and at different times.

* [CMU Pose, Illumination, and Expression (PIE)](http://www.flintbox.com/public/project/4742/): 
41,368 color images of 68 people in 13 different poses. Images labeled with expressions. (Pay for shipping)

* [The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS)](https://zenodo.org/record/1188976#.XIDeOBMzaL4): 
7,356 video and audio recordings of 24 professional actors. 8 emotions each at two intensities.  Files labelled with expression. Perceptual validation ratings provided by 319 raters.

* [SCFace](http://www.scface.org/): 
Color images of faces at various angles. Location of facial features extracted. Coordinates of features given.

* [YouTube Faces DB](https://www.cs.tau.ac.il/~wolf/ytfaces/): 
Videos of 1,595 different people gathered from YouTube. Each clip is between 48 and 6,070 frames.  Identity of those appearing in videos and descriptors.

* [300 videos in-the-Wild](https://ibug.doc.ic.ac.uk/resources/300-VW/): 
The 300 Videos in the Wild (300-VW) dataset contains videos for facial landmarks tracking. Specifically, this dataset includes 114 lengthy videos (approx. 1 min each) with 68 markup landmark points annotated densely.

* [Grammatical Facial Expressions Dataset](https://archive.ics.uci.edu/ml/datasets/Grammatical+Facial+Expressions): 
Grammatical Facial Expressions from Brazilian Sign Language.

* [CMU Face Images Data Set](http://archive.ics.uci.edu/ml/datasets/cmu+face+images): 
Images of faces. Each person is photographed multiple times to capture different expressions.

* [Yale Face Database](http://vision.ucsd.edu/content/yale-face-database): 
The Yale Face Database (size 6.4MB) contains 165 grayscale images in GIF format of 15 individuals. There are 11 images per subject, one per different facial expression or configuration: center-light, w/glasses, happy, left-light, w/no glasses, normal, right-light, sad, sleepy, surprised, and wink.

* [Cohn-Kanade AU-Coded Expression Database](http://www.pitt.edu/~emotion/ck-spread.htm): 
Large database of images with labels for expressions.

* [FaceScrub](http://vintage.winklerbros.net/facescrub.html): 
Images of public figures scrubbed from image searching.

* [Skin Segmentation Data Set ](https://archive.ics.uci.edu/ml/datasets/skin+segmentation): 
Randomly sampled color values from face images.

* [Bosphorus](http://bosphorus.ee.boun.edu.tr/Home.aspx): 
The Bosphorus Database is intended for research on 3D and 2D human face processing tasks including expression recognition, facial action unit detection, facial action unit intensity estimation, face recognition under adverse conditions, deformable face modeling, and 3D face reconstruction. There are 105 subjects and 4666 faces in the database. 

* [UOY 3D-Face](http://www-users.cs.york.ac.uk/~nep/research/UoYfaces/): 
The UoY 3D face dataset is a set of 3D images of the human face and consists of around 5000 3D images of approximately 350 people (15 models each). The data collection was planned and implemented by Tom Heseltine during his PhD in 3D Face Recognition at the Department of Computer Science, University of York.

* [Biometrics Ideal Test](http://biometrics.idealtest.org/): 
Biometrics Ideal Test (or BIT for short) is a website for biometric database sharing and algorithm evaluation. Our mission is to facilitate biometrics research and development by providing quality public services to biometric researchers. You are welcome to register an account in BIT so that you can download publicly available iris, face, fingerprint, palmprint, multi-spectral palm and handwriting. 

* [BU-3DFE](http://www.cs.binghamton.edu/~lijun/Research/3DFE/3DFE_Analysis.html): 
neutral face, and 6 expressions: anger, happiness, sadness, surprise, disgust, fear (4 levels). 3D images extracted.

* [Face Recognition Grand Challenge Dataset](https://www.nist.gov/programs-projects/face-recognition-grand-challenge-frgc): 
Up to 22 samples for each subject. Expressions: anger, happiness, sadness, surprise, disgust, puffy. 3D Data.

* [3D-RMA](http://www.sic.rma.ac.be/~beumier/DB/3d_rma.html): 
Up to 100 subjects, expressions mostly neutral. Several poses as well.

* [Specs on Faces](https://sites.google.com/view/sof-dataset): 
A collection of 42,592 images for 112 persons (66 males and 46 females) who wear glasses under different illumination conditions.  
Format: Images  
Default task: Gender classification - face detection - eyeglasses detection - emotion recognition - facial landmark detection


* [IMDB-WIKI](https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/): 
IMDB and Wikipedia face images with gender and age labels.

#### Action Recognition
* [Human Motion DataBase (HMDB51)](http://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/): 
51 action categories, each containing at least 101 clips, extracted from a range of sources.

* [TV Human Interaction Dataset](http://www.robots.ox.ac.uk/~alonso/tv_human_interactions.html): 
Consists of 300 video clips collected from over 20 different TV shows and containing 4 interactions: hand shakes, high fives, hugs and kisses, as well as clips that don't contain any of the interactions. 

* [UT Interaction](http://cvrc.ece.utexas.edu/SDHA2010/Human_Interaction.html): 
People acting out one of 6 actions (shake-hands, point, hug, push, kick, and punch) sometimes with multiple groups in the same video clip.

* [UT Kinect](http://cvrc.ece.utexas.edu/KinectDatasets/HOJ3D.html): 
10 different people performing one of 6 actions (walk, sit down, stand up, pick up, carry, throw, push, pull, wave hands and clap hands) in an office setting.

* [Berkeley Multimodal Human Action Database (MHAD)](http://tele-immersion.citris-uc.org/berkeley_mhad): 
Recordings of a single person performing 12 actions

* [UCF101 – Action Recognition Data Set](https://www.crcv.ucf.edu/research/data-sets/human-actions/ucf101/): 
Self described as "a dataset of 101 human actions classes from videos in the wild." Dataset is large with over 27 hours of video.

* [THUMOS Dataset](http://www.thumos.info/download.html): 
Large video dataset for action classification.

* [Activitynet](http://activity-net.org/): 
A Large-Scale Video Benchmark for Human Activity Understanding

* [MSP-AVATAR](https://ecs.utdallas.edu/research/researchlabs/msp-lab/MSP-AVATAR.html): 
The MSP-Avatar corpus is a motion capture database which explores the role of discourse functions in non-verbal human interactions. This database comprises three sessions of recordings of spontaneous dyadic interactions between six actors. The scenarios are designed to elicit different types of discourse-related gestures in the actors. 

* [LILiR Twotalk Corpus](http://www.ee.surrey.ac.uk/Projects/LILiR/twotalk_corpus/): 
The LILiR Twotalk corpus is comprised of four conversations of two person (dyadic) conversations recorded with minimal constraints on participant behavior. Four conversations of 12 minutes were recorded with two PAL progressive scan cameras, one microphone and eight subjects. Annotation was performed by multiple annotators from various cultures on 527 clips, extracted from the longer videos. The conversation participants were only instructed to be seated and to talk. 

* [MEXAction2](http://mexculture.cnam.fr/xwiki/bin/view/Datasets/Mex+action+dataset): 
Video dataset for action localization and spotting

#### Object Detection and Recognition
* [Visual Genome](https://visualgenome.org/api/v0/api_home.html): 
Visual Genome is a dataset, a knowledge base, an ongoing effort to connect structured image concepts to language.

* [DAVIS: Densely Annotated VIdeo Segmentation](https://davischallenge.org/): 
150 video sequences containing 10459 frames with a total of 376 objects annotated.

* [T-LESS: An RGB-D Dataset for 6D Pose Estimation of Texture-less Objects](http://cmp.felk.cvut.cz/t-less/): 
30 industry-relevant objects. 39K training and 10K test images from each of three sensors. Two types of 3D models for each object.

* [Berkeley 3-D Object Dataset](http://kinectdata.com/): 
A quality depth sensor, the Microsoft Kinect, is now in millions of homes. Yet robust household object detection is still not a reality. To get there, we are collecting a massive, crowd-sourced, and challenging 3-D object dataset.

* [Berkeley Segmentation Data Set and Benchmarks 500 (BSDS500)](https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/): 
500 natural images, explicitly separated into disjoint train, validation and test subsets + benchmarking code. Based on BSDS300.

* [Microsoft Common Objects in Context (COCO)](http://cocodataset.org/#home): 
Complex everyday scenes of common objects in their natural context.

* [SUN Database](https://groups.csail.mit.edu/vision/SUN/): 
Very large scene and object recognition database.

* [Open Images](https://storage.googleapis.com/openimages/web/index.html): 
A Large set of images listed as having CC BY 2.0 license with image-level labels and bounding boxes spanning thousands of classes.

* [TV News Channel Commercial Detection Dataset](http://archive.ics.uci.edu/ml/datasets/tv+news+channel+commercial+detection+dataset): 
TV commercials and news broadcasts.

* [Caltech 101](http://www.vision.caltech.edu/Image_Datasets/Caltech101/): 
Pictures of objects belonging to 101 categories. About 40 to 800 images per category. Most categories have about 50 images. Collected in September 2003 by Fei-Fei Li, Marco Andreetto, and Marc 'Aurelio Ranzato.  The size of each image is roughly 300 x 200 pixels.

* [Caltech-256](https://authors.library.caltech.edu/7694/): 
Large dataset of images for object classification.

* [SIFT10M Data Set ](https://archive.ics.uci.edu/ml/datasets/SIFT10M): 
SIFT features of Caltech-256 dataset.

* [Cityscapes Dataset](https://www.cityscapes-dataset.com/): 
The Cityscapes Dataset focuses on semantic understanding of urban street scenes.

* [PASCAL VOC Dataset](http://host.robots.ox.ac.uk/pascal/VOC/): 
Large number of images for classification tasks.

* [CIFAR-10 CIFAR-100 Dataset](https://www.cs.toronto.edu/~kriz/cifar.html): 
Many small, low-resolution, images of 10 classes of objects.

* [CINIC-10](https://datashare.is.ed.ac.uk/handle/10283/3192): 
CINIC-10 is an augmented extension of CIFAR-10. It contains the images from CIFAR-10 (60,000 images, 32x32 RGB pixels) and a selection of ImageNet database images (210,000 images downsampled to 32x32). It was compiled as a 'bridge' between CIFAR-10 and ImageNet, for benchmarking machine learning applications. It is split into three equal subsets - train, validation, and test - each of which contain 90,000 images.

* [Fashion MNIST](https://www.kaggle.com/zalando-research/fashionmnist): 
A MNIST-like fashion product database

* [notMNIST dataset](https://www.kaggle.com/lubaroli/notmnist): 
Some publicly available fonts and extracted glyphs from them to make a dataset similar to MNIST. There are 10 classes, with letters A-J taken from different fonts.

* [The German Traffic Sign Detection Benchmark](http://benchmark.ini.rub.de/?section=gtsdb&subsection=dataset): 
Images from vehicles of traffic signs on German roads. These signs comply with UN standards and therefore are the same as in other countries.

* [KITTI Vision Benchmark Suite!](http://benchmark.ini.rub.de/?section=gtsdb&subsection=dataset): 
Autonomous vehicles driving through a mid-size city captured images of various areas using cameras and laser scanners.

* [Linnaeus 5 dataset](http://chaladze.com/l5/): 
Images of 5 classes of objects.

* [FieldSAFE](https://vision.eng.au.dk/fieldsafe/): 
Multi-modal dataset for obstacle detection in agriculture including stereo camera, thermal camera, web camera, 360-degree camera, lidar, radar, and precise localization.

* [11K Hands](https://sites.google.com/view/11khands): 
11,076 hand images (1600 x 1200 pixels) of 190 subjects, of varying ages between 18 – 75 years old, for gender recognition and biometric identification.

* [CORe50](https://vlomonaco.github.io/core50/): 
Specifically designed for Continuous/Lifelong Learning and Object Recognition, is a collection of more than 500 videos (30fps) of 50 domestic objects belonging to 10 different categories.


#### Handwriting and character recognition
* [Artificial Characters Dataset](https://data.world/uci/artificial-characters): 
Artificially generated data describing the structure of 10 capital English letters.

* [Letter Dataset](https://archive.ics.uci.edu/ml/datasets/letter+recognition): 
Upper case printed letters.

* [Character Trajectories Dataset](https://archive.ics.uci.edu/ml/datasets/Character+Trajectories): 
Labeled samples of pen tip trajectories for people writing simple characters.

* [Chars74K Dataset](http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/): 
Character recognition in natural images of symbols used in both English and Kannada.

* [UJI Pen Characters Dataset](https://archive.ics.uci.edu/ml/datasets/UJI+Pen+Characters): 
Isolated handwritten characters

* [Gisette Dataset](https://archive.ics.uci.edu/ml/datasets/Gisette): 
Handwriting samples from the often-confused 4 and 9 characters.

* [MNIST database](http://yann.lecun.com/exdb/mnist/): 
The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.

* [Optical Recognition of Handwritten Digits Dataset](https://archive.ics.uci.edu/ml/datasets/optical+recognition+of+handwritten+digits): 
Normalized bitmaps of handwritten data.

* [Pen-Based Recognition of Handwritten Digits Dataset](https://archive.ics.uci.edu/ml/datasets/Pen-Based+Recognition+of+Handwritten+Digits): 
Handwritten digits on electronic pen-tablet.

* [Semeion Handwritten Digit Dataset ](https://archive.ics.uci.edu/ml/datasets/Pen-Based+Recognition+of+Handwritten+Digits): 
1593 handwritten digits from around 80 persons were scanned, stretched in a rectangular box 16x16 in a gray scale of 256 values.Then each pixel of each image was scaled into a bolean (1/0) value using a fixed threshold.   
Each person wrote on a paper all the digits from 0 to 9, twice. The commitment was to write the digit the first time in the normal way (trying to write each digit accurately) and the second time in a fast way (with no accuracy). 

* [Semeion Handwritten Digit Dataset ](https://archive.ics.uci.edu/ml/datasets/Pen-Based+Recognition+of+Handwritten+Digits): 
1593 handwritten digits from around 80 persons were scanned, stretched in a rectangular box 16x16 in a gray scale of 256 values.Then each pixel of each image was scaled into a bolean (1/0) value using a fixed threshold.   
Each person wrote on a paper all the digits from 0 to 9, twice. The commitment was to write the digit the first time in the normal way (trying to write each digit accurately) and the second time in a fast way (with no accuracy). 

* [HASYv2](https://zenodo.org/record/259444#.XISuGhMzaL4):
HASY contains 32px x 32px images of 369 symbol classes. In total, HASY contains over 150,000 instances of handwritten symbols.
 
* [Noisy Handwritten Bangla Datase](https://csc.lsu.edu/~saikat/noisy-bangla/):
Includes Handwritten Numeral Dataset (10 classes) and Basic Character Dataset (50 classes), each dataset has three types of noise: white gaussian, motion blur, and reduced contrast.

#### Aerial images
* [Inria Aerial Image Labeling Dataset](https://project.inria.fr/aerialimagelabeling/):
The Inria Aerial Image Labeling addresses a core topic in remote sensing: the automatic pixelwise labeling of aerial imagery 

* [Aerial Image Segmentation Dataset](http://jiangyeyuan.com/ASD/Aerial%20Image%20Segmentation%20Dataset.html):
80 high-resolution aerial images with spatial resolution ranging from 0.3 to 1.0.

* [KIT AIS Data Set](http://www.ipf.kit.edu/downloads.php):
Multiple labeled training and evaluation datasets of aerial images of crowds (Vehicles and people).

* [Wilt Dataset](http://archive.ics.uci.edu/ml/datasets/wilt):
This data set contains some training and testing data from a remote sensing study by Johnson et al. (2013) that involved detecting diseased trees in Quickbird imagery. There are few training samples for the 'diseased trees' class (74) and many for 'other land cover' class (4265). 

* [Forest type mapping Dataset](https://archive.ics.uci.edu/ml/datasets/Forest+type+mapping):
Satellite imagery of forests in Japan.  
  Format: text  
  Default task: Classification

* [Overhead Imagery Research Dataset](https://sourceforge.net/projects/oirds/):
Overhead Imagery Research Data Set (OIRDS) - an annotated data library & tools to aid in the development of computer vision algorithms.  
  Format: Images, text  
  Default task: Classification

* [SpaceNet](https://spacenetchallenge.github.io/):
SpaceNet is a corpus of commercial satellite imagery and labeled training data.  
  Format: Images  
  Default task: Classification, Object Identification

* [UC Merced Land Use Dataset](http://weegee.vision.ucmerced.edu/datasets/landuse.html):
These images were manually extracted from large images from the USGS National Map Urban Area Imagery collection for various urban areas around the US.  
  Format: Image   
  Default task: Classification

* [SAT-4 and SAT-6 Airborne Dataset](https://csc.lsu.edu/~saikat/deepsat/):
Images were extracted from the National Agriculture Imagery Program (NAIP) dataset. SAT-4 has four broad land cover classes, includes barren land, trees, grassland and a class that consists of all land cover classes other than the above three. SAT-6 has six broad land cover classes, includes barren land, trees, grassland, roads, buildings and water bodies.  
  Format: Image   
  Default task: Classification


#### Other images
* [Quantum simulations of an electron in a two dimensional potential well](https://nrc-digital-repository.canada.ca/eng/view/object/?id=1343ae23-cebf-45c6-94c3-ddebdb2f23c6):
Labelled images of raw input to a simulation of 2d Quantum mechanics  
Format: Image   
Default task: Regression

* [MPII Cooking Activities Dataset](https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/research/human-activity-recognition/mpii-cooking-activities-dataset/):
Videos and images of various cooking activities.  
Format: Labeled video, images, text   
Default task: Classification

* [MPII Emo Dataset](https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/research/human-activity-recognition/mpiiemo-dataset/):
Emotion Recognition from Embedded Bodily Expressions and Speech during Dyadic Interactions.  
Format: Labeled video, images, text   
Default task: Classification

* [FAMOS Dataset](http://sip.unige.ch/famos):
5,000 unique microstructures, all samples have been acquired 3 times with two different cameras..  
Format: Labeled video, images, text   
Default task: Classification

* [PharmaPack Dataset](http://sip.unige.ch/projects/snf-200021-165672/pharmapack/index.php?cID=292#download):
1,000 unique classes with 54 images per class  
Format: Images and .mat files   
Default task: Fine-grain classification

* [Stanford Dogs Dataset](http://vision.stanford.edu/aditya86/ImageNetDogs/):
Images of 120 breeds of dogs from around the world.  
Format: Images, text   
Default task: Fine-grain classification

* [The Oxford-IIIT Pet Dataset](http://www.robots.ox.ac.uk/~vgg/data/pets/):
37 category pet dataset with roughly 200 images for each class. The images have a large variations in scale, pose and lighting. All images have an associated ground truth annotation of breed, head ROI, and pixel level trimap segmentation.  
Format: Images, text   
Default task: Classification, object detection

* [Corel Image Features Data Set](https://archive.ics.uci.edu/ml/datasets/corel+image+features):
Database of images with features extracted.  
Format: text   
Default task: Classification, object detection

* [Online Video Characteristics and Transcoding Time Dataset](https://archive.ics.uci.edu/ml/datasets/Online+Video+Characteristics+and+Transcoding+Time+Dataset):
Transcoding times for various different videos and video properties.  
Format: text   
Default task: Regression

* [Microsoft Sequential Image Narrative Dataset (SIND)](http://visionandlanguage.net/VIST/):
Dataset for sequential vision-to-language.  
Format: Images, text   
Default task: Visual storytelling

* [Caltech-UCSD Birds-200-2011 Dataset](http://www.vision.caltech.edu/visipedia/CUB-200-2011.html):
Large dataset of images of birds.  
Format: Images, text   
Default task: Classification.

* [YouTube-8M](https://research.google.com/youtube8m/):
Large and diverse labeled video dataset.  
Format: Video, text  
Default task: Video classification.

* [YFCC100M](https://sites.google.com/site/videosearch100m/home):
This YFCC100M dataset contains a list of photos and videos on Yahoo! Flickr, 
which are licensed under one of the Creative Commons copyright licenses.  
Format: Video, Image, Text  
Default task: Video and Image classification.

* [Discrete LIRIS-ACCEDE](http://liris-accede.ec-lyon.fr/):
Short videos annotated for valence and arousal.  
Format: Video  
Default task: Video emotion elicitation detection.

* [Continuous LIRIS-ACCEDE](http://liris-accede.ec-lyon.fr/database.php):
Long videos annotated for valence and arousal while also collecting Galvanic Skin Response.  
Format: Video  
Default task: Video emotion elicitation detection.

* [MediaEval LIRIS-ACCEDE](http://liris-accede.ec-lyon.fr/database.php):
Extension of Discrete LIRIS-ACCEDE including annotations for violence levels of the films.  
Format: Video  
Default task: Video emotion elicitation detection.

* [Leeds Sports Pose](http://sam.johnson.io/research/lsp.html):
Articulated human pose annotations in 2000 natural sports images from Flickr.  
Format: Images plus .mat file labels  
Default task: Human pose estimation.

* [Leeds Sports Pose Extended Training](http://sam.johnson.io/research/lspet.html):
Articulated human pose annotations in 10,000 natural sports images from Flickr.  
Format: Images plus .mat file labels  
Default task: Human pose estimation.

* [Leeds Sports Pose Extended Training](http://sam.johnson.io/research/lspet.html):
6 different real multiple choice-based exams (735 answer sheets and 33,540 answer boxes) to evaluate computer vision techniques and systems developed for multiple choice test assessment systems.  
Format: Images and .mat file labels 
Default task: Development of multiple choice test assessment systems.

* [Surveillance Videos](https://sites.google.com/view/surveillance-videos-dataset/home):
Real surveillance videos cover a large surveillance time (7 days with 24 hours each).  
Format: Videos 
Default task: Data compression.

* [Can We See Photosynthesis?](https://sites.google.com/view/mafifi/publications/can-we-see-photosynthesis):
32 videos for eight live and eight dead leaves recorded under both DC and AC lighting conditions.  
Format: Videos 
Default task: Liveness detection of plants.

## Text data
#### Reviews
* [Amazon reviews](https://s3.amazonaws.com/amazon-reviews-pds/readme.html): 
Amazon Customer Reviews (a.k.a. Product Reviews) is one of Amazon’s iconic products. In a period of over two decades since the first review in 1995, millions of Amazon customers have contributed over a hundred million reviews to express opinions and describe their experiences regarding products on the Amazon.com website. This makes Amazon Customer Reviews a rich source of information for academic researchers in the fields of Natural Language Processing (NLP), Information Retrieval (IR), and Machine Learning (ML), amongst others. Accordingly, we are releasing this data to further research in multiple disciplines related to understanding customer product experiences. Specifically, this dataset was constructed to represent a sample of customer evaluations and opinions, variation in the perception of a product across geographical regions, and promotional intent or bias in reviews.  
Format: Text   
Default task: Classification, sentiment analysis.

* [Car Evaluation Data Set](https://archive.ics.uci.edu/ml/datasets/car+evaluation): 
Car properties and their overall acceptability.  
Format: Text  
Default task: Classification.

* [YouTube Comedy Slam Preference Dataset](https://archive.ics.uci.edu/ml/datasets/YouTube+Comedy+Slam+Preference+Data): 
User vote data for pairs of videos shown on YouTube. Users voted on funnier videos.  
Format: Text  
Default task: Classification.

* [Skytrax User Reviews Dataset](https://github.com/quankiquanki/skytrax-reviews-dataset): 
A scraped dataset created from all user reviews found on Skytrax (www.airlinequality.com). It is unknown under which license Skytrax published these reviews. However, the reviews are accessible by anyone with a browser and the robots.txt on their website did not specifically prohibit the scraping of them.  
Format: Text  
Default task: Classification, regression.

* [Teaching Assistant Evaluation Dataset](https://archive.ics.uci.edu/ml/datasets/teaching+assistant+evaluation): 
The data consist of evaluations of teaching performance over three regular semesters and two summer semesters of 151 teaching assistant (TA) assignments at the Statistics Department of the University of Wisconsin-Madison. The scores were divided into 3 roughly equal-sized categories ("low", "medium", and "high") to form the class variable.  
Format: Text  
Default task: Classification.

#### News Articles
* [NYSK Dataset](http://archive.ics.uci.edu/ml/datasets/NYSK?ref=datanews.io): 
English news articles about the case relating to allegations of sexual assault against the former IMF director Dominique Strauss-Kahn.  
Format: XML, text   
Default task: Sentiment analysis, topic extraction.

* [The Reuters Corpus Volum1 1 & 2](https://trec.nist.gov/data/reuters/reuters.html): 
Large corpus of Reuters news stories in multiple languages.  
Format: XML, text   
Default task: Classification, clustering, summarization.

* [Thomson Reuters Text Research Collection (TRC2)](https://trec.nist.gov/data/reuters/reuters.html): 
The TRC2 corpus comprises 1,800,370 news stories covering the period from 2008-01-01 00:00:03 to 2009-02-28 23:54:14 or 2,871,075,221 bytes, and was initially made available to participants of the 2009 blog track at the Text Retrieval Conference (TREC), to supplement the BLOGS08 corpus (that contains results of a large blog crawl carried out at the University of Glasgow). TRC2 is distributed via web download.  
Format: XML, text   
Default task: Classification, clustering, summarization.

* [Saudi Newspapers Corpus ](https://github.com/ParallelMazen/SaudiNewsNet): 
31,030 Arabic newspaper articles.  
Format: json   
Default task: Summarization, clustering.

* [RE3D (Relationship and Entity Extraction Evaluation Dataset)](https://github.com/dstl/re3d): 
Entity and Relation marked data from various news and government sources. Sponsored by Dstl.  
Format: json   
Default task: Classification, Entity and Relation recognition

* [ABC Australia News Corpus](https://www.kaggle.com/therohk/million-headlines): 
Entire news corpus of ABC Australia from 2003 to 2017.  
Format: CSV   
Default task:Clustering, Events, Sentiment


## Voice Datasets
* [Common Voice](https://voice.mozilla.org/en/datasets): 
Common Voice is a massive global database of donated voices that lets 
anyone quickly and easily train voice-enabled apps in potentially every 
language.

* [(Singapore) National Speech Corpus](https://www.imda.gov.sg/NationalSpeechCorpus): 
First announced in November 2017, the first version of the National Speech 
Corpus (NSC) is now available for download. It contains 2,000 hours of locally 
accented audio and corresponding text transcriptions. There are more than 40,000 
unique words within the text transcriptions comprising local words such as “Tanjong Pagar”, 
“ice kachang”, or “nasi lemak”. The data is made available via the Singapore Open Data Licence. 
Automatic speech recognition engines use multiple corpus collections 
(collectively called corpora) to accurately train themselves to interpret spoken 
words and transcribe them. The NSC thus enables global technology providers to 
provide speech-related applications such as voice assistants, for use here. The NSC 
will be continually updated.


## IoT Datasets

* [CGIAR dataset](http://www.ccafs-climate.org/): 
High-resolution climate datasets for a variety of fields including agricultural

* [Educational Process Mining](http://archive.ics.uci.edu/ml/datasets/Educational+Process+Mining+%28EPM%29%3A+A+Learning+Analytics+Data+Set): 
Recordings of 115 subjects’ activities through a logging application while learning with an educational simulator

* [Commercial Building Energy Dataset](http://combed.github.io/): 
Energy related data set from a commercial building where data is sampled more than once a minute.

* [Individual household electric power consumption](http://archive.ics.uci.edu/ml/datasets/Individual+household+electric+power+consumption): 
One-minute sampling rate over a period of almost 4 years

* [AMPds dataset](http://ampds.org/): 
AMPds contains electricity, water, and natural gas measurements at one minute intervals for 2 years of monitoring.

* [UK Domestic Appliance-Level](http://www.doc.ic.ac.uk/∼dk3810/data/): 
Power demand from five houses. In each house both the whole-house mains power demand as well as power demand from individual appliances are recorded.

* [PhysioBank databases (Healthcare)](https://physionet.org/physiobank/database/): 
Archive of over 80 physiological datasets.

* [Saarbruecken Voice Database (Healthcare)](http://www.stimmdatebank.coli.uni-saarland.de/help_en.php4  ): 
A collection of voice recordings from more than 2000 persons for pathological voice detection.

* [T-LESS (Industry)](http://cmp.felk.cvut.cz/t-less/): 
An RGB-D dataset and evaluation methodology for detection and 6D pose estimation of texture-less objects

* [CityPulse Dataset Collection (Smart City)](http://iot.ee.surrey.ac.uk:8080/datasets.html): 
Road Traffic Data, Pollution Data, Weather, Parking

* [Open Data Institute – node Trento (Smart City)](http://theodi.fbk.eu/openbigdata/): 
Weather, Air quality,  Electricity, Telecommunication

* [Malaga datasets (Smart City)](http://datosabiertos.malaga.eu/dataset): 
A broad range of categories such as energy, ITS, weather, Industry, Sport, etc.

* [Gas sensors for home activity monitoring (Smart Home)](http://archive.ics.uci.edu/ml/datasets/Gas+sensors+for+home+activity+monitoring): 
Recordings of 8 gas sensors under three conditions including background, wine and banana presentations.

* [CASAS datasets for activities of daily living (Smart Home)](http://ailab.wsu.edu/casas/datasets.html): 
Several public datasets related to Activities of Daily Living (ADL) performance in a two story home, an apartment, and an office settings.

* [ARAS Human Activity Dataset (Smart Home)](https://www.cmpe.boun.edu.tr/aras/): 
Human activity recognition datasets collected from two real houses with multiple residents during two months.

* [MERLSense Data (Smart Home)](http://www.merl.com/wmd): 
Motion sensor data of residual traces from a network of over 200 sensors for two years, containing over 50 million records.

* [SportVU (Sport)](http://go.stats.com/sportvu): 
Video of basketball and soccer games captured from 6 cameras.

* [RealDisp (Sport)](http://orestibanos.com/datasets.htm  ): 
Includes a wide range of physical activities (warm up, cool down and fitness exercises).

* [Taxi Service Trajectory (Transportation)](http://www.geolink.pt/ecmlpkdd2015-challenge/dataset.html): 
Trajectories performed by all the 442 taxis running in the city of Porto, in Portugal.

* [GeoLife GPS Trajectories (Transportation)](https://www.microsoft.com/en-us/download/details.aspx?id=52367): 
A GPS trajectory by a sequence of time-stamped points

* [T-Drive trajectory data (Transportation)](https://www.microsoft.com/en-us/research/publication/t-drive-trajectory-data-sample/): 
Contains a one-week trajectories of 10,357 taxis

* [Chicago Bus Traces data (Transportation)](http://www.ibr.cs.tu-bs.de/users/mdoering/bustraces/): 
Bus traces from the Chicago Transport Authority for 18 days with a rate between 20 and 40 seconds.

* [Uber trip data (Transportation)](https://github.com/fivethirtyeight/uber-tlc-foil-response): 
About 20 million Uber pickups in New York City during 12 months

* [Traffic Sign Recognition (Transportation)](https://figshare.com/articles/Traffic_Sign_Recognition_Testsets/4597795): 
Three datasets: Korean daytime, Korean nighttime, and German daytime traffic signs based on Vienna traffic rules.

* [DDD17 (Transportation)](http://sensors.ini.uzh.ch/databases.html): 
End-To-End DAVIS Driving Dataset.


## Recommender Datasets
#### Book
  - [Book Crossing](http://www2.informatik.uni-freiburg.de/~cziegler/BX/):: The BookCrossing (BX) dataset was collected by Cai-Nicolas in a 4-week crawl (August / September 2004) from the Book-Crossing community
  
#### Dating
  - [Dating Agency](http://www.occamslab.com/petricek/data/):: This dataset contains 17,359,346 anonymous ratings of 168,791 profiles made by 135,359 LibimSeTi users as dumped on April 4, 2006.

#### E-commerce
  - [Amazon](http://jmcauley.ucsd.edu/data/amazon/): This dataset contains product reviews and metadata from Amazon, including 142.8 million reviews spanning May 1996 - July 2014
  - [Retailrocket recommender system dataset](https://www.kaggle.com/retailrocket/ecommerce-dataset):: The dataset consists of three files: a file with behaviour data (events.csv), a file with item properties (item_properties.сsv) and a file, which describes category tree (category_tree.сsv). The data has been collected from a real-world ecommerce website. 

#### Music
  - [Amazon Music](http://jmcauley.ucsd.edu/data/amazon/): This digital music dataset contains reviews and metadata from Amazon
  - [Yahoo Music](https://webscope.sandbox.yahoo.com/catalog.php?datatype=r):: This dataset represents a snapshot of the Yahoo! Music community's preferences for various musical artists.
  - [LastFM (Implicit)](https://grouplens.org/datasets/hetrec-2011/):: This dataset contains social networking, tagging, and music artist listening information from a set of 2K users from Last.fm online music system.
  - [Million Song Dataset](https://labrosa.ee.columbia.edu/millionsong/):: The Million Song Dataset is a freely-available collection of audio features and metadata for a million contemporary popular music tracks.

#### Movies
  - [MovieLens](https://grouplens.org/datasets/movielens/): GroupLens Research has collected and made available rating datasets from their movie web site 
  - [Yahoo Movies](https://webscope.sandbox.yahoo.com/catalog.php?datatype=r):: This dataset contains ratings for songs collected from two different sources. The first source consists of ratings supplied by users during normal interaction with Yahoo! Music services. 
  - [CiaoDVD](https://www.librec.net/datasets.html):: CiaoDVD is a dataset crawled from the entire category of DVDs from the dvd.ciao.co.uk website in December, 2013
  - [FilmTrust](https://www.librec.net/datasets.html):: FilmTrust is a small dataset crawled from the entire FilmTrust website in June, 2011
  - [Netflix](http://academictorrents.com/details/9b13183dc4d60676b773c9e2cd6de5e5542cee9a):: This is the official data set used in the Netflix Prize competition. 
  - [Cornell University](http://www.cs.cornell.edu/people/pabo/movie-review-data/): 
  Cornell University - Movie-review data for use in sentiment-analysis experiments 
  - [Douban Dataset](https://www.cse.cuhk.edu.hk/irwin.king.new/pub/data/douban):
  This is the anonymized Douban dataset contains 129,490 unique users and 58,541 unique movie items. The total number of movie ratings is 16,830,839. For the social friend network, there are a total of 1,692,952 claimed social relationships.
  - [Epinions Dataset](http://www.trustlet.org/epinions.html):
Epinions is a website where people can review products. Users can register for free and 
start writing subjective reviews about many different types of items (software, music, 
television show, hardware, office appliances, ...). 
A peculiar characteristics of Epinions is that users are paid according to how much a review 
is found useful (Income Share program).

  
#### Games

  - [Steam Video Games](https://www.kaggle.com/tamber/steam-video-games/data): This dataset is a list of user behaviors, with columns: user-id, game-title, behavior-name, value. The behaviors included are 'purchase' and 'play'. The value indicates the degree to which the behavior was performed - in the case of 'purchase' the value is always 1, and in the case of 'play' the value represents the number of hours the user has played the game. 

#### Jokes
  - [Jester](http://www.ieor.berkeley.edu/~goldberg/jester-data/): This Joke dataset contains 4.1 million continuous ratings (-10.00 to +10.00) of 100 jokes from 73,496 users
  
#### Food
  - [Chicago Entree](http://archive.ics.uci.edu/ml/datasets/Entree+Chicago+Recommendation+Data): This dataset contains a record of user interactions with the Entree Chicago restaurant recommendation system.
  
#### Anime
  - [Anime Recommendations Database](https://www.kaggle.com/CooperUnion/anime-recommendations-database): This data set contains information on user preference data from 73,516 users on 12,294 anime. Each user is able to add anime to their completed list and give it a rating and this data set is a compilation of those ratings.

#### Scholarly Paper
  - [National University of Singapore - Scholarly Paper Recommendation ](http://www.comp.nus.edu.sg/~sugiyama/SchPaperRecData.html): 

#### Healthcare 
  - [Medicare.gov](https://data.medicare.gov/):
  This site provides direct access to the official data from the Centers for Medicare & 
  Medicaid Services (CMS) that are used on the Medicare.gov Compare Websites and 
  Directories. The goal of the site is to make these CMS data readily available in open, 
  accessible, and machine-readable formats.  Includes Hospital Compare DataSet, Nursing Home compare datasets and more.
  
  
  
## Anomaly Data
* [Numenta Anomaly Benchmark (NAB)](https://www.kaggle.com/boltzmannbrain/nab): 
Data are ordered, timestamped, single-valued metrics. All data files contain anomalies, unless otherwise noted.


## Text Classification
 - [Movie Lens Dataset](https://grouplens.org/datasets/movielens/latest/):
  The data set was collected over various periods of time, depending on the size of the set. Stable benchmark dataset. 20 million ratings and 465,000 tag applications applied to 27,000 movies by 138,000 users. Includes tag genome data with 12 million relevance scores across 1,100 tags.  
  Format: text  
  Default task: Text classification, Regression, clustering.
  
 - [OPIN-RANK REVIEW Dataset](https://github.com/kavgan/OpinRank/tree/master):
  This dataset contains full reviews for cars and hotels collected from TripAdvisor (~259,000 reviews) and Edmunds (~42,230 reviews).  
  Format: text  
  Default task: classification, Sentiment analysis, clustering.
  
 - [Cyber-Trolls Dataset](https://dataturks.com/projects/abhishek.narayanan/Dataset%20for%20Detection%20of%20Cyber-Trolls):
  Dataset used to classify tweets as aggressive or not to help fight trolls. The dataset has 20001 items of which 20001 items have been manually labeled. There are 2 categories 1(Cyber-Aggressive) and 0 (Non-Cyber-Aggressive). These are Human labeled dataset.  
  Format: Text  
  Default Task: Text classification
  
 - [Chat Messages By Category Dataset](https://dataturks.com/projects/yogi15172853/Manual%20labeling%20for%20categories):
  The dataset has 20001 items of which 68 items have been manually labeled. A text classification dataset with 8 classes like Alcohol & Drugs, Profanity & Obscenity, Sex, religion etc.  
  Format: Text  
  Default Task: Text classification
  
 - [SPAMBASE Dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/):
  The Spam base data set includes 4601 observations corresponding to email messages, 1813 of which are spam. From the original email messages, 58 different attributes were computed. One would either have to blind such non-spam indicators or get a very wide collection of non-spam to generate a general purpose spam filter.  
  Format: Text  
  Default task: Spam detection, classification
  
 - [Sentiment140 Dataset](https://www.kaggle.com/kazanova/sentiment140):
  Sentiment140 allows you to discover the sentiment of a brand, product, or topic on Twitter. use causes Brand management (e.g. Windows 10), Polling (e.g. Obama), Planning a purchase (e.g. Kindle)  
  Format: Text  
  Default Task: Sentiment analysis
  
  - [Distress classification Dataset](https://dataturks.com/projects/benjamin.gurr/Distress%20News%20Classification%20Model%20Output):
  This is a text classification dataset for classification of news headlines/articles based on whether they are distressed or not. The dataset has 1983 items of which 1983 items have been manually labeled. Labels are distress and not-distress.  
  Format: Text  
  Default Task: Text classification

  - [Blog Authorship Dataset](http://u.cs.biu.ac.il/~koppel/BlogCorpus.htm):
  The Blog Authorship Corpus consists of the collected posts of 19,320 bloggers gathered from blogger.com in August 2004. The corpus incorporates a total of 681,288 posts and over 140 million words or approximately 35 posts and 7250 words per person. Each blog is presented as a separate file, the name of which indicates a blogger id# and the blogger’s self-provided gender, age, industry and astrological sign. For each age group, there is an equal number of male and female bloggers.  
  Format: Text  
  Default Task: Sentiment analysis, summarization, classification
  
  - [Musk Dataset](https://archive.ics.uci.edu/ml/datasets/Musk+%28Version+2%29):
  This dataset describes a set of 102 molecules of which 39 are judged by human experts to be musks and the remaining 63 molecules are judged to be non-musks. The goal is to learn to predict whether new molecules will be musks or non-musks. Because bonds can rotate, a single molecule can adopt many different shapes. This many-to-one relationship between feature vectors and molecules is called the “multiple instance problem”. When learning a classifier for this data, the classifier should classify a molecule as “musk” if ANY of its conformations is classified as a musk. A molecule should be classified as “non-musk” if NONE of its conformations is classified as a musk.  
  Format: Text  
  Default Task:Text Classification

  - [Commentary Dataset](https://dataturks.com/projects/zhiqiyubupt/comment):
  Comments in the matches classified as humor, praise, stats, teasing etc.. The dataset has 1408 items of which 1287 items have been manually labeled. These labels are classified into 23 categories such as injury, audience, feeling, communication, teasing etc.  
  Format: Text  
  Default Task:Text Classification

  - [Emotion Classification Dataset ](https://dataturks.com/projects/tedysuwega/EMOTION):
  The Dataset consists of data which is labeled with different sentiments. The dataset has 269 items of which 269 items have been manually labeled. These are divided into 7 categories happy, sad, excited, angry, scared, tender, others  
  Format: Text  
  Default Task:Text Classification

  - [NSDUH Dataset](https://www.datafiles.samhsa.gov/study-dataset/national-survey-drug-use-and-health-2016-nsduh-2016-ds0001-nid17185):
  The National Survey on Drug Use and Health (NSDUH) series, formerly titled National Household Survey on Drug Abuse, is a major source of statistical information on the use of illicit drugs, alcohol, and tobacco and on mental health issues among members of the U.S. There are 55,268 instances in the Dataset.  
  Format: Text  
  Default Task:Text classification, regression
 
  - [Zoo Dataset](https://archive.ics.uci.edu/ml/datasets/Zoo):
  A simple database containing 17 Boolean-valued attributes. Animals are classed into 7 categories and features are given for each.
  Format: Text  
  Default Task:Text classification
  
  - [URL Dataset](https://archive.ics.uci.edu/ml/datasets/URL+Reputation):
  This Dataset is to construct a real-time system that uses machine learning techniques to detect malicious URLs (spam, phishing, exploits, and so on). To this end, we have explored techniques that involve classifying URLs based on their lexical and host-based features, as well as online learning to process large numbers of examples and adapt quickly to evolving URLs over time.  
  Format: Text  
  Default Task:Text classification
  
  
## Machine Translation
 - [Movie Lens Dataset](https://grouplens.org/datasets/movielens/latest/):
  The data set was collected over various periods of time, depending on the size of the set. Stable benchmark dataset. 20 million ratings and 465,000 tag applications applied to 27,000 movies by 138,000 users. Includes tag genome data with 12 million relevance scores across 1,100 tags.  
  Format: text  
  Default task: Text classification, Regression, clustering.

  
  
  
 
  
  